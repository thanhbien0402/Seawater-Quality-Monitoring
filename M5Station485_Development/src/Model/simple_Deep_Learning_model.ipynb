{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8yy4EEfg7H6"
      },
      "source": [
        "# **Theory for training simple Deep Learning model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnqJTvpaw89z"
      },
      "source": [
        "Để phân tích dữ liệu dựa trên các cảm biến như độ pH (pH sensor), độ khử oxy (ORP sensor), độ dẫn điện (EC sensor), và độ đục nước (TUR sensor) và dự đoán dữ liệu tương lai sử dụng mô hình Long Short-Term Memory (LSTM), bạn cần thực hiện các bước trong pipeline dưới đây. LSTM rất phù hợp để xử lý các bài toán chuỗi thời gian, vì nó có khả năng ghi nhớ các thông tin dài hạn trong chuỗi.\n",
        "\n",
        "**Pipeline cho mô hình LSTM**\n",
        "\n",
        "**Bước 1: Chuẩn bị dữ liệu**\n",
        "\n",
        "**1. Thu thập dữ liệu:** Đảm bảo bạn đã thu thập đủ dữ liệu từ các cảm biến trong một khoảng thời gian đủ dài. Các cảm biến pH, ORP, EC, TUR có thể có các tín hiệu liên tục theo thời gian (chuỗi thời gian).\n",
        "\n",
        "**2. Tiền xử lý dữ liệu:**\n",
        "\n",
        "* Xử lý giá trị thiếu: Nếu có giá trị thiếu trong dữ liệu, bạn có thể điền giá trị này bằng phương pháp interpolation hoặc sử dụng giá trị trung bình.\n",
        "\n",
        "* Làm sạch dữ liệu: Loại bỏ các giá trị ngoại lệ hoặc điều chỉnh dữ liệu nếu cần.\n",
        "\n",
        "* Chuẩn hóa dữ liệu: Các giá trị từ các cảm biến này có thể có các thang đo khác nhau, vì vậy bạn nên chuẩn hóa chúng về cùng một thang đo (ví dụ: sử dụng Min-Max Scaling hoặc Standardization).\n",
        "\n",
        "* Chia dữ liệu thành các cửa sổ thời gian: LSTM yêu cầu dữ liệu đầu vào ở dạng chuỗi, vì vậy bạn cần chuyển dữ liệu thành các cửa sổ thời gian (time windows). Ví dụ, bạn có thể tạo một cửa sổ thời gian bao gồm các giá trị của 5 hoặc 10 thời điểm trước để dự đoán giá trị tại thời điểm tiếp theo.\n",
        "\n",
        "**3. Chia dữ liệu thành tập huấn luyện và kiểm tra:**\n",
        "\n",
        "* Chia dữ liệu thành các phần huấn luyện và kiểm tra (ví dụ: 80% cho huấn luyện và 20% cho kiểm tra).\n",
        "\n",
        "* Đảm bảo rằng dữ liệu huấn luyện và kiểm tra không chồng chéo lên nhau nếu bạn đang sử dụng dữ liệu chuỗi thời gian.\n",
        "\n",
        "**Bước 2: Xây dựng mô hình LSTM**\n",
        "\n",
        "**1. Xây dựng mô hình LSTM:** Mô hình LSTM sẽ gồm các lớp LSTM với các tham số thích hợp. Bạn sẽ cần một lớp đầu vào, sau đó một hoặc nhiều lớp LSTM, và cuối cùng là một lớp Dense để xuất ra giá trị dự báo.\n",
        "\n",
        "**2. Cấu trúc mô hình LSTM:**\n",
        "\n",
        "* Input Layer: Kích thước của đầu vào phải phù hợp với số lượng cửa sổ thời gian bạn muốn sử dụng.\n",
        "\n",
        "* LSTM Layer(s): Có thể thêm một hoặc nhiều lớp LSTM với các tham số như số lượng units, activation function, và return_sequences.\n",
        "\n",
        "* Dense Layer: Lớp Dense sẽ được sử dụng để đưa ra dự báo cuối cùng.\n",
        "\n",
        "* Output Layer: Một đơn vị đầu ra (nếu bạn đang dự đoán một giá trị liên tục).\n",
        "\n",
        "**Bước 3: Huấn luyện mô hình**\n",
        "\n",
        "**1. Chọn loss function và optimizer:**\n",
        "\n",
        "* Loss function: Dùng MSE (Mean Squared Error) cho các bài toán hồi quy.\n",
        "\n",
        "* Optimizer: Adam là một lựa chọn phổ biến cho mô hình LSTM vì khả năng điều chỉnh learning rate tự động.\n",
        "\n",
        "**2. Huấn luyện mô hình:**\n",
        "\n",
        "* Huấn luyện mô hình trên dữ liệu huấn luyện và kiểm tra trên dữ liệu kiểm tra.\n",
        "\n",
        "* Lưu ý điều chỉnh số epoch và batch size sao cho phù hợp với dữ liệu của bạn.\n",
        "\n",
        "**Bước 4: Đánh giá mô hình**\n",
        "\n",
        "**1. Đánh giá hiệu suất mô hình:**\n",
        "\n",
        "* Sử dụng các chỉ số như MSE (Mean Squared Error) hoặc RMSE (Root Mean Squared Error) để đánh giá hiệu quả của mô hình.\n",
        "\n",
        "* Visualize kết quả dự báo so với dữ liệu thực tế để đánh giá khả năng dự báo.\n",
        "\n",
        "**Bước 5: Dự báo dữ liệu tương lai**\n",
        "\n",
        "Sau khi huấn luyện mô hình, bạn có thể sử dụng mô hình này để dự báo các giá trị trong tương lai dựa trên dữ liệu quá khứ.\n",
        "\n",
        "**Mối Quan Hệ Giữa Các Dữ Liệu:**\n",
        "\n",
        "* pH và ORP: pH có thể ảnh hưởng trực tiếp đến ORP. Nước có pH thấp (axit) thường sẽ có ORP thấp, trong khi pH cao (kiềm) có thể làm tăng ORP.\n",
        "\n",
        "* EC và pH: Nước có độ mặn cao thường có pH ổn định hơn do ảnh hưởng của các ion muối trong nước. Do đó, khi EC cao, pH có thể có xu hướng ổn định.\n",
        "\n",
        "* EC và TUR: Nếu độ đục của nước cao, có thể dẫn đến giảm khả năng dẫn điện (EC) vì sự hiện diện của các chất bẩn làm giảm khả năng ion hóa trong nước. Tuy nhiên, trường hợp này có thể không đúng hoàn toàn nếu có sự hiện diện của nhiều ion hòa tan.\n",
        "\n",
        "* TUR và ORP: Độ đục nước cao có thể làm giảm lượng oxy hòa tan trong nước, từ đó ảnh hưởng đến giá trị ORP.\n",
        "\n",
        "**Tóm lại, nước biển có chất lượng tốt thường có:**\n",
        "\n",
        "* pH: 7.5 - 8.5\n",
        "\n",
        "* ORP: 200 mV - 300 mV\n",
        "\n",
        "* EC: 40,000 µS/cm - 60,000 µS/cm\n",
        "\n",
        "* TUR: 0 - 10 NTU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qba_NxWrfxEz"
      },
      "source": [
        "# **Start to build the simple Deep Learning model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJGTAn-jgYXS",
        "outputId": "91d957f6-a163-495d-f0ca-f190649f5720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install --upgrade tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, GRU\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p6IdaGfWa4-U",
        "outputId": "17530c40-1b2a-4e7a-8948-b94a74f6aa51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0877 - val_loss: 0.0426\n",
            "Epoch 2/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0476 - val_loss: 0.0409\n",
            "Epoch 3/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0452 - val_loss: 0.0403\n",
            "Epoch 4/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0437 - val_loss: 0.0399\n",
            "Epoch 5/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0417 - val_loss: 0.0404\n",
            "Epoch 6/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0400\n",
            "Epoch 7/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0414 - val_loss: 0.0397\n",
            "Epoch 8/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0407 - val_loss: 0.0396\n",
            "Epoch 9/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0401 - val_loss: 0.0394\n",
            "Epoch 10/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0402 - val_loss: 0.0393\n",
            "Epoch 11/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0393 - val_loss: 0.0395\n",
            "Epoch 12/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0394\n",
            "Epoch 13/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0396\n",
            "Epoch 14/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0396 - val_loss: 0.0394\n",
            "Epoch 15/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0392 - val_loss: 0.0395\n",
            "Epoch 16/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0394 - val_loss: 0.0396\n",
            "Epoch 17/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0394 - val_loss: 0.0394\n",
            "Epoch 18/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0385 - val_loss: 0.0395\n",
            "Epoch 19/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0382 - val_loss: 0.0395\n",
            "Epoch 20/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0396\n",
            "Epoch 21/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.0397\n",
            "Epoch 22/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0379 - val_loss: 0.0397\n",
            "Epoch 23/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0397\n",
            "Epoch 24/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0397\n",
            "Epoch 25/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.0397\n",
            "Epoch 26/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - val_loss: 0.0397\n",
            "Epoch 27/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0398\n",
            "Epoch 28/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0398\n",
            "Epoch 29/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0379 - val_loss: 0.0399\n",
            "Epoch 30/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0368 - val_loss: 0.0398\n",
            "Epoch 31/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0376 - val_loss: 0.0399\n",
            "Epoch 32/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - val_loss: 0.0400\n",
            "Epoch 33/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - val_loss: 0.0400\n",
            "Epoch 34/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.0400\n",
            "Epoch 35/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.0402\n",
            "Epoch 36/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - val_loss: 0.0399\n",
            "Epoch 37/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0371 - val_loss: 0.0403\n",
            "Epoch 38/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.0402\n",
            "Epoch 39/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0403\n",
            "Epoch 40/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.0404\n",
            "Epoch 41/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0371 - val_loss: 0.0403\n",
            "Epoch 42/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0406\n",
            "Epoch 43/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0404\n",
            "Epoch 44/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.0404\n",
            "Epoch 45/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0407\n",
            "Epoch 46/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.0405\n",
            "Epoch 47/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.0404\n",
            "Epoch 48/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0406\n",
            "Epoch 49/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0408\n",
            "Epoch 50/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0355 - val_loss: 0.0408\n",
            "Epoch 51/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0359 - val_loss: 0.0409\n",
            "Epoch 52/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0410\n",
            "Epoch 53/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0409\n",
            "Epoch 54/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0409\n",
            "Epoch 55/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0409\n",
            "Epoch 56/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0410\n",
            "Epoch 57/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0417\n",
            "Epoch 58/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - val_loss: 0.0411\n",
            "Epoch 59/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0413\n",
            "Epoch 60/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - val_loss: 0.0413\n",
            "Epoch 61/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0340 - val_loss: 0.0412\n",
            "Epoch 62/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0349 - val_loss: 0.0413\n",
            "Epoch 63/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0344 - val_loss: 0.0414\n",
            "Epoch 64/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.0416\n",
            "Epoch 65/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0343 - val_loss: 0.0416\n",
            "Epoch 66/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0338 - val_loss: 0.0414\n",
            "Epoch 67/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - val_loss: 0.0414\n",
            "Epoch 68/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - val_loss: 0.0416\n",
            "Epoch 69/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - val_loss: 0.0416\n",
            "Epoch 70/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - val_loss: 0.0416\n",
            "Epoch 71/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - val_loss: 0.0417\n",
            "Epoch 72/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - val_loss: 0.0417\n",
            "Epoch 73/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - val_loss: 0.0418\n",
            "Epoch 74/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0340 - val_loss: 0.0418\n",
            "Epoch 75/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0333 - val_loss: 0.0420\n",
            "Epoch 76/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - val_loss: 0.0420\n",
            "Epoch 77/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - val_loss: 0.0423\n",
            "Epoch 78/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - val_loss: 0.0418\n",
            "Epoch 79/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - val_loss: 0.0421\n",
            "Epoch 80/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0336 - val_loss: 0.0421\n",
            "Epoch 81/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0323 - val_loss: 0.0422\n",
            "Epoch 82/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0335 - val_loss: 0.0419\n",
            "Epoch 83/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0330 - val_loss: 0.0420\n",
            "Epoch 84/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0330 - val_loss: 0.0422\n",
            "Epoch 85/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: 0.0421\n",
            "Epoch 86/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.0423\n",
            "Epoch 87/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.0419\n",
            "Epoch 88/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.0421\n",
            "Epoch 89/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0422\n",
            "Epoch 90/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0333 - val_loss: 0.0424\n",
            "Epoch 91/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0323 - val_loss: 0.0423\n",
            "Epoch 92/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0327 - val_loss: 0.0421\n",
            "Epoch 93/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0327 - val_loss: 0.0425\n",
            "Epoch 94/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0422\n",
            "Epoch 95/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0425\n",
            "Epoch 96/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.0427\n",
            "Epoch 97/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0425\n",
            "Epoch 98/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0426\n",
            "Epoch 99/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: 0.0430\n",
            "Epoch 100/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0330 - val_loss: 0.0425\n",
            "Epoch 101/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.0428\n",
            "Epoch 102/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0427\n",
            "Epoch 103/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0428\n",
            "Epoch 104/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0426\n",
            "Epoch 105/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.0427\n",
            "Epoch 106/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.0425\n",
            "Epoch 107/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0426\n",
            "Epoch 108/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0324 - val_loss: 0.0429\n",
            "Epoch 109/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.0431\n",
            "Epoch 110/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0425\n",
            "Epoch 111/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0429\n",
            "Epoch 112/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0425\n",
            "Epoch 113/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0321 - val_loss: 0.0429\n",
            "Epoch 114/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0315 - val_loss: 0.0429\n",
            "Epoch 115/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0323 - val_loss: 0.0431\n",
            "Epoch 116/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0429\n",
            "Epoch 117/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.0430\n",
            "Epoch 118/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0324 - val_loss: 0.0428\n",
            "Epoch 119/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0425\n",
            "Epoch 120/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.0429\n",
            "Epoch 121/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0428\n",
            "Epoch 122/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0430\n",
            "Epoch 123/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0323 - val_loss: 0.0430\n",
            "Epoch 124/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0428\n",
            "Epoch 125/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0321 - val_loss: 0.0430\n",
            "Epoch 126/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0432\n",
            "Epoch 127/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.0430\n",
            "Epoch 128/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0432\n",
            "Epoch 129/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0431\n",
            "Epoch 130/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0319 - val_loss: 0.0429\n",
            "Epoch 131/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0314 - val_loss: 0.0433\n",
            "Epoch 132/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0434\n",
            "Epoch 133/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0318 - val_loss: 0.0432\n",
            "Epoch 134/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0434\n",
            "Epoch 135/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0319 - val_loss: 0.0438\n",
            "Epoch 136/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0308 - val_loss: 0.0431\n",
            "Epoch 137/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0433\n",
            "Epoch 138/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0431\n",
            "Epoch 139/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0432\n",
            "Epoch 140/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0314 - val_loss: 0.0433\n",
            "Epoch 141/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0432\n",
            "Epoch 142/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.0433\n",
            "Epoch 143/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0314 - val_loss: 0.0433\n",
            "Epoch 144/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0430\n",
            "Epoch 145/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0431\n",
            "Epoch 146/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0435\n",
            "Epoch 147/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0435\n",
            "Epoch 148/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0314 - val_loss: 0.0435\n",
            "Epoch 149/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0306 - val_loss: 0.0432\n",
            "Epoch 150/150\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0430\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,624\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,510</span> (56.68 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,510\u001b[0m (56.68 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,836</span> (18.89 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,836\u001b[0m (18.89 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,674</span> (37.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,674\u001b[0m (37.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "file_path = '/content/gdrive/MyDrive/Lab4_IOT/Seawater_Quality_Monitoring.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "sensor_cols = ['pH', 'ORP', 'EC', 'TUR']\n",
        "data = df[sensor_cols].values\n",
        "\n",
        "# standardize data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "def create_sequences(dataset, time_step = 10, seq_cols = None, label_col = None):\n",
        "    if isinstance(dataset, np.ndarray):\n",
        "        dataset = pd.DataFrame(dataset, columns=seq_cols)\n",
        "\n",
        "    # df_zeros = pd.DataFrame(np.zeros((time_step - 1, len(dataset.columns))), columns = dataset.columns)\n",
        "    # dataset = df_zeros.append(dataset, ignore_index = True)\n",
        "\n",
        "    df_zeros = pd.DataFrame(np.zeros((time_step - 1, len(dataset.columns))), columns=dataset.columns)\n",
        "    dataset = pd.concat([df_zeros, dataset], ignore_index=True)\n",
        "\n",
        "    data_array = dataset[seq_cols].values\n",
        "\n",
        "    X, y = [], []\n",
        "    num_elements = data_array.shape[0]\n",
        "\n",
        "    # create time series and label for each sample\n",
        "    for start, stop in zip(range(0, num_elements - time_step), range(time_step, num_elements)):\n",
        "        X.append(data_array[start:stop, :])\n",
        "        y.append(dataset[label_col].iloc[stop])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, time_step = 10, seq_cols = sensor_cols, label_col = sensor_cols)\n",
        "\n",
        "# divide data upon on size\n",
        "train_size = int(len(X) * 0.6)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# build and train the simple DL model\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(4)) # make sure 4 output: pH, ORP, EC, TUR\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate = 0.001), loss = 'mean_squared_logarithmic_error')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs = 150,\n",
        "    batch_size = 32,\n",
        "    validation_data = (X_test, y_test),\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "# model.save('/content/gdrive/MyDrive/Lab4_IOT/my_LSTM_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qbh33Zi9qcpu",
        "outputId": "3d57fedd-372e-43b4-e0cb-423458727ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model size: 0.09 MB\n",
            "Saved artifact at '/tmp/tmpabkg7wco'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10, 4), dtype=tf.float32, name='input_layer_11')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133036210399440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133036210396368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133036210399632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133036210392912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133036210395216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133036210397712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "----- Time 1 -----\n",
            "pH sensor: Predicted value = 7.8704, Actual value = 7.9742, RMSE value = 0.1038\n",
            "ORP sensor: Predicted value = 246.0390, Actual value = 262.9229, RMSE value = 16.8839\n",
            "EC sensor: Predicted value = 46014.3047, Actual value = 49688.8762, RMSE value = 3674.5715\n",
            "TUR sensor: Predicted value = 3.4175, Actual value = 3.5551, RMSE value = 0.1376\n",
            "----- Time 2 -----\n",
            "pH sensor: Predicted value = 7.9798, Actual value = 7.6395, RMSE value = 0.3403\n",
            "ORP sensor: Predicted value = 247.2401, Actual value = 263.0315, RMSE value = 15.7914\n",
            "EC sensor: Predicted value = 46597.3945, Actual value = 54978.4485, RMSE value = 8381.0540\n",
            "TUR sensor: Predicted value = 4.9757, Actual value = 9.2310, RMSE value = 4.2553\n",
            "----- Time 3 -----\n",
            "pH sensor: Predicted value = 8.0070, Actual value = 7.5030, RMSE value = 0.5040\n",
            "ORP sensor: Predicted value = 255.5460, Actual value = 206.6660, RMSE value = 48.8800\n",
            "EC sensor: Predicted value = 50133.9844, Actual value = 57988.1132, RMSE value = 7854.1288\n",
            "TUR sensor: Predicted value = 6.0552, Actual value = 6.3116, RMSE value = 0.2564\n",
            "----- Time 4 -----\n",
            "pH sensor: Predicted value = 7.9147, Actual value = 8.4579, RMSE value = 0.5432\n",
            "ORP sensor: Predicted value = 247.3851, Actual value = 243.0845, RMSE value = 4.3006\n",
            "EC sensor: Predicted value = 48619.1211, Actual value = 48333.7434, RMSE value = 285.3777\n",
            "TUR sensor: Predicted value = 3.2934, Actual value = 3.4426, RMSE value = 0.1492\n",
            "----- Time 5 -----\n",
            "pH sensor: Predicted value = 8.0167, Actual value = 7.6428, RMSE value = 0.3739\n",
            "ORP sensor: Predicted value = 240.6660, Actual value = 237.8633, RMSE value = 2.8027\n",
            "EC sensor: Predicted value = 48385.0625, Actual value = 40292.9708, RMSE value = 8092.0917\n",
            "TUR sensor: Predicted value = 5.4631, Actual value = 5.0931, RMSE value = 0.3700\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('/content/gdrive/MyDrive/Lab4_IOT/my_LSTM_model.keras')\n",
        "\n",
        "model_size = os.path.getsize('/content/gdrive/MyDrive/Lab4_IOT/my_LSTM_model.keras')\n",
        "print(f\"Model size: {model_size / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# converter.experimental_enable_resource_variables = True\n",
        "# converter.target_spec.supported_ops = [\n",
        "#     tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "#     tf.lite.OpsSet.SELECT_TF_OPS\n",
        "# ]\n",
        "# converter._experimental_lower_tensor_list_ops = False\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/gdrive/MyDrive/Lab4_IOT/model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# predict and return to original value\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_inv = scaler.inverse_transform(y_pred)\n",
        "y_test_inv = scaler.inverse_transform(y_test)\n",
        "\n",
        "# r2 = r2_score(y_test_inv, y_pred_inv)\n",
        "# print(f\"Overall R² value: {r2:.4f}\")\n",
        "\n",
        "sensor_names = ['pH', 'ORP', 'EC', 'TUR']\n",
        "\n",
        "for i in range(len(y_test_inv)):\n",
        "    print(f\"----- Time {i + 1} -----\")\n",
        "\n",
        "    for j in range(4):\n",
        "        pred = y_pred_inv[i][j]\n",
        "        actual = y_test_inv[i][j]\n",
        "        rmse = np.sqrt(mean_squared_error([actual], [pred]))\n",
        "        # r2_sensor = r2_score([actual], [pred])\n",
        "\n",
        "        print(f\"{sensor_names[j]} sensor: Predicted value = {pred:.4f}, Actual value = {actual:.4f}, RMSE value = {rmse:.4f}\")\n",
        "\n",
        "    time.sleep(5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
